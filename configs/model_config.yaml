experiment_name: "bert-bgg-comment-score-predictor"
model_name: "distilbert/distilbert-base-uncased"
tokenizer_path: "distilbert/distilbert-base-uncased"
train_data_path: "/tmp/data/train.dataset"
val_data_path: "/tmp/data/eval.dataset"
output_dir: "/tmp/models/checkpoints/distilbert-finetuned"
num_labels: 11  # Binary classification
learning_rate: 2e-5
epochs: 3
warmup_steps: 100
per_device_train_batch_size: 16
per_device_eval_batch_size: 16
weight_decay: 0.01